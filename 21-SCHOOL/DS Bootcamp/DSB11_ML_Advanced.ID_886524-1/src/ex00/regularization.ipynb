{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Импорт необходимых библиотек\n\nimport pandas as pd  # Для работы с данными в табличном формате\nimport numpy as np   # Для математических операций и работы с массивами\n\n# Модули sklearn для машинного обучения\nfrom sklearn.model_selection import train_test_split, StratifiedKFold  # Разделение данных и кросс-валидация\nfrom sklearn.linear_model import LogisticRegression  # Логистическая регрессия\nfrom sklearn.svm import SVC  # Support Vector Classifier (метод опорных векторов)\nfrom sklearn.tree import DecisionTreeClassifier  # Дерево решений\nfrom sklearn.ensemble import RandomForestClassifier  # Случайный лес\nfrom sklearn.metrics import accuracy_score, confusion_matrix  # Метрики качества\n\nimport pickle  # Для сохранения обученной модели\nimport warnings\nwarnings.filterwarnings('ignore')  # Отключаем предупреждения для чистоты вывода"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Загрузка данных из CSV файла\n# Файл dayofweek.csv содержит информацию о коммитах: uid, lab name, количество попыток, час коммита\n# Целевая переменная - день недели (dayofweek)\ndf = pd.read_csv('../data/dayofweek.csv')\ndf.head()  # Выводим первые 5 строк для проверки данных"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Разделение данных на признаки (X) и целевую переменную (y)\n# X - все колонки кроме 'dayofweek' (признаки: uid, lab name, trials, hour)\n# y - колонка 'dayofweek' (целевая переменная - день недели от 0 до 6)\nX = df.drop('dayofweek', axis=1)\ny = df['dayofweek']\n\nprint(f\"Размер матрицы признаков X: {X.shape}\")  # (количество образцов, количество признаков)\nprint(f\"Размер вектора целевой переменной y: {y.shape}\")\nprint(f\"\\nРаспределение классов (дней недели):\\n{y.value_counts().sort_index()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Разделение данных на обучающую и тестовую выборки\n# test_size=0.2 - 20% данных уходит в тест, 80% в обучение\n# random_state=21 - фиксируем случайность для воспроизводимости результатов\n# stratify=y - сохраняем пропорции классов в обеих выборках (важно при несбалансированных классах)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    random_state=21, \n    stratify=y\n)\n\nprint(f\"Размер обучающей выборки: {X_train.shape[0]} образцов\")\nprint(f\"Размер тестовой выборки: {X_test.shape[0]} образцов\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Базовая модель логистической регрессии\n# random_state=21 - для воспроизводимости\n# fit_intercept=False - не добавляем свободный член (bias)\n# max_iter=1000 - максимальное число итераций для сходимости алгоритма\nmodel = LogisticRegression(random_state=21, fit_intercept=False, max_iter=1000)\n\n# Стратифицированная K-fold кросс-валидация\n# n_splits=10 - делим данные на 10 частей\n# shuffle=True - перемешиваем данные перед разбиением\n# Стратификация сохраняет пропорции классов в каждом фолде\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=21)\n\ntrain_scores = []\nvalid_scores = []\n\n# Цикл по фолдам кросс-валидации\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    # Разделяем данные на текущий train и validation фолд\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    # Обучаем модель на train фолде\n    model.fit(X_tr, y_tr)\n    \n    # Оцениваем качество на train и validation\n    train_score = model.score(X_tr, y_tr)\n    valid_score = model.score(X_val, y_val)\n    \n    train_scores.append(train_score)\n    valid_scores.append(valid_score)\n    \n    print(f\"train -  {train_score:.5f}   |   valid -  {valid_score:.5f}\")\n\n# Итоговые метрики по всем фолдам\nprint(f\"Average accuracy on crossval is {np.mean(valid_scores):.5f}\")\nprint(f\"Std is {np.std(valid_scores):.5f}\")  # Стандартное отклонение показывает стабильность модели"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Логистическая регрессия с L2 регуляризацией (Ridge)\n# L2 регуляризация уменьшает величину всех коэффициентов, но не обнуляет их\n# Помогает предотвратить переобучение (overfitting)\n# C=1.0 - обратный коэффициент регуляризации (чем меньше C, тем сильнее регуляризация)\nmodel_l2 = LogisticRegression(penalty='l2', random_state=21, fit_intercept=False, max_iter=1000, C=1.0)\n\nvalid_scores_l2 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    model_l2.fit(X_tr, y_tr)\n    valid_score = model_l2.score(X_val, y_val)\n    valid_scores_l2.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность с L2 регуляризацией: {np.mean(valid_scores_l2):.5f}\")\nprint(f\"Std: {np.std(valid_scores_l2):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Логистическая регрессия с L1 регуляризацией (Lasso)\n# L1 регуляризация может обнулять некоторые коэффициенты\n# Полезна для отбора признаков (feature selection) - незначимые признаки получат вес 0\n# solver='saga' - алгоритм оптимизации, который поддерживает L1\nmodel_l1 = LogisticRegression(penalty='l1', solver='saga', random_state=21, fit_intercept=False, max_iter=1000, C=1.0)\n\nvalid_scores_l1 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    model_l1.fit(X_tr, y_tr)\n    valid_score = model_l1.score(X_val, y_val)\n    valid_scores_l1.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность с L1 регуляризацией: {np.mean(valid_scores_l1):.5f}\")\nprint(f\"Std: {np.std(valid_scores_l1):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Логистическая регрессия БЕЗ регуляризации\n# penalty=None - отключаем регуляризацию полностью\n# Модель может переобучиться на тренировочных данных\nmodel_none = LogisticRegression(penalty=None, random_state=21, fit_intercept=False, max_iter=1000)\n\nvalid_scores_none = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    model_none.fit(X_tr, y_tr)\n    valid_score = model_none.score(X_val, y_val)\n    valid_scores_none.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность без регуляризации: {np.mean(valid_scores_none):.5f}\")\nprint(f\"Std: {np.std(valid_scores_none):.5f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Базовая модель SVM (Support Vector Machine - метод опорных векторов)\n# probability=True - включаем расчет вероятностей (нужно для некоторых метрик)\n# kernel='linear' - линейное ядро (простейший случай, разделяющая гиперплоскость)\n# Другие ядра: 'rbf', 'poly', 'sigmoid'\nsvm_model = SVC(probability=True, kernel='linear', random_state=21)\n\nsvm_train_scores = []\nsvm_valid_scores = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    svm_model.fit(X_tr, y_tr)\n    \n    train_score = svm_model.score(X_tr, y_tr)\n    valid_score = svm_model.score(X_val, y_val)\n    \n    svm_train_scores.append(train_score)\n    svm_valid_scores.append(valid_score)\n    \n    print(f\"train -  {train_score:.5f}   |   valid -  {valid_score:.5f}\")\n\nprint(f\"Средняя точность SVM на кросс-валидации: {np.mean(svm_valid_scores):.5f}\")\nprint(f\"Std: {np.std(svm_valid_scores):.5f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# SVM с параметром регуляризации C=0.1\n# C - параметр регуляризации (штраф за ошибки классификации)\n# Маленькое C (0.1) = сильная регуляризация, модель более простая, меньше переобучение\n# Большое C = слабая регуляризация, модель может переобучиться\nsvm_c01 = SVC(probability=True, kernel='linear', random_state=21, C=0.1)\n\nvalid_scores_svm_c01 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    svm_c01.fit(X_tr, y_tr)\n    valid_score = svm_c01.score(X_val, y_val)\n    valid_scores_svm_c01.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность SVM с C=0.1: {np.mean(valid_scores_svm_c01):.5f}\")\nprint(f\"Std: {np.std(valid_scores_svm_c01):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# SVM с параметром регуляризации C=10\n# Большое C = слабая регуляризация\n# Модель пытается классифицировать все обучающие примеры правильно\n# Может привести к переобучению на шумных данных\nsvm_c10 = SVC(probability=True, kernel='linear', random_state=21, C=10)\n\nvalid_scores_svm_c10 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    svm_c10.fit(X_tr, y_tr)\n    valid_score = svm_c10.score(X_val, y_val)\n    valid_scores_svm_c10.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность SVM с C=10: {np.mean(valid_scores_svm_c10):.5f}\")\nprint(f\"Std: {np.std(valid_scores_svm_c10):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Базовая модель дерева решений (Decision Tree)\n# max_depth=10 - максимальная глубина дерева (регуляризация)\n# Чем глубже дерево, тем сложнее модель и выше риск переобучения\n# Без ограничения глубины дерево может создать отдельный лист для каждого образца\ntree_model = DecisionTreeClassifier(max_depth=10, random_state=21)\n\ntree_train_scores = []\ntree_valid_scores = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    tree_model.fit(X_tr, y_tr)\n    \n    train_score = tree_model.score(X_tr, y_tr)\n    valid_score = tree_model.score(X_val, y_val)\n    \n    tree_train_scores.append(train_score)\n    tree_valid_scores.append(valid_score)\n    \n    print(f\"train -  {train_score:.5f}   |   valid -  {valid_score:.5f}\")\n\nprint(f\"Средняя точность дерева на кросс-валидации: {np.mean(tree_valid_scores):.5f}\")\nprint(f\"Std: {np.std(tree_valid_scores):.5f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Дерево с max_depth=5 (более простая модель)\n# Меньшая глубина = более сильная регуляризация\n# Модель более обобщенная, меньше риск переобучения\n# Но может недообучиться (underfitting) если данные сложные\ntree_d5 = DecisionTreeClassifier(max_depth=5, random_state=21)\n\nvalid_scores_tree_d5 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    tree_d5.fit(X_tr, y_tr)\n    valid_score = tree_d5.score(X_val, y_val)\n    valid_scores_tree_d5.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность дерева с max_depth=5: {np.mean(valid_scores_tree_d5):.5f}\")\nprint(f\"Std: {np.std(valid_scores_tree_d5):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Дерево с max_depth=15 (более сложная модель)\n# Большая глубина = слабая регуляризация\n# Модель может лучше улавливать сложные паттерны\n# Но выше риск переобучения на шуме в данных\ntree_d15 = DecisionTreeClassifier(max_depth=15, random_state=21)\n\nvalid_scores_tree_d15 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    tree_d15.fit(X_tr, y_tr)\n    valid_score = tree_d15.score(X_val, y_val)\n    valid_scores_tree_d15.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность дерева с max_depth=15: {np.mean(valid_scores_tree_d15):.5f}\")\nprint(f\"Std: {np.std(valid_scores_tree_d15):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Базовая модель случайного леса (Random Forest)\n# Ансамбль из множества деревьев решений\n# n_estimators=50 - количество деревьев в лесу\n# max_depth=14 - максимальная глубина каждого дерева\n# Случайный лес менее склонен к переобучению чем одно дерево благодаря:\n# 1. Bagging - каждое дерево обучается на случайной подвыборке данных\n# 2. Случайный выбор признаков для каждого разделения\nrf_model = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)\n\nrf_train_scores = []\nrf_valid_scores = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    rf_model.fit(X_tr, y_tr)\n    \n    train_score = rf_model.score(X_tr, y_tr)\n    valid_score = rf_model.score(X_val, y_val)\n    \n    rf_train_scores.append(train_score)\n    rf_valid_scores.append(valid_score)\n    \n    print(f\"train -  {train_score:.5f}   |   valid -  {valid_score:.5f}\")\n\nprint(f\"Средняя точность Random Forest на кросс-валидации: {np.mean(rf_valid_scores):.5f}\")\nprint(f\"Std: {np.std(rf_valid_scores):.5f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Random Forest с n_estimators=100, max_depth=10\n# Больше деревьев (100) = более стабильные предсказания\n# Меньшая глубина (10) = более сильная регуляризация\n# Баланс между сложностью модели и обобщающей способностью\nrf_100_10 = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=21)\n\nvalid_scores_rf_100_10 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    rf_100_10.fit(X_tr, y_tr)\n    valid_score = rf_100_10.score(X_val, y_val)\n    valid_scores_rf_100_10.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность RF (100 деревьев, depth=10): {np.mean(valid_scores_rf_100_10):.5f}\")\nprint(f\"Std: {np.std(valid_scores_rf_100_10):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Random Forest с n_estimators=50, max_depth=20\n# Меньше деревьев (50), но каждое глубже (20)\n# Более сложные деревья могут улавливать сложные паттерны\n# Но также могут переобучаться\nrf_50_20 = RandomForestClassifier(n_estimators=50, max_depth=20, random_state=21)\n\nvalid_scores_rf_50_20 = []\n\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    rf_50_20.fit(X_tr, y_tr)\n    valid_score = rf_50_20.score(X_val, y_val)\n    valid_scores_rf_50_20.append(valid_score)\n    print(f\"valid -  {valid_score:.5f}\")\n\nprint(f\"\\nСредняя точность RF (50 деревьев, depth=20): {np.mean(valid_scores_rf_50_20):.5f}\")\nprint(f\"Std: {np.std(valid_scores_rf_50_20):.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Сравнение всех обученных моделей\n# Собираем средние результаты кросс-валидации в словарь\n# Сортируем по убыванию точности для выбора лучшей модели\nresults = {\n    'LogReg baseline': np.mean(valid_scores),\n    'LogReg L2': np.mean(valid_scores_l2),\n    'LogReg L1': np.mean(valid_scores_l1),\n    'LogReg no penalty': np.mean(valid_scores_none),\n    'SVM baseline': np.mean(svm_valid_scores),\n    'SVM C=0.1': np.mean(valid_scores_svm_c01),\n    'SVM C=10': np.mean(valid_scores_svm_c10),\n    'Tree baseline': np.mean(tree_valid_scores),\n    'Tree d=5': np.mean(valid_scores_tree_d5),\n    'Tree d=15': np.mean(valid_scores_tree_d15),\n    'RF baseline': np.mean(rf_valid_scores),\n    'RF 100-10': np.mean(valid_scores_rf_100_10),\n    'RF 50-20': np.mean(valid_scores_rf_50_20),\n}\n\nprint(\"Рейтинг моделей по точности на кросс-валидации:\")\nprint(\"-\" * 45)\nfor model_name, score in sorted(results.items(), key=lambda x: x[1], reverse=True):\n    print(f\"{model_name:25s}: {score:.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Обучение лучшей модели на полной обучающей выборке\n# Выбираем Random Forest как обычно показывающий хорошие результаты\n# Теперь обучаем на ВСЕХ тренировочных данных (не только на фолдах)\nbest_model = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)\nbest_model.fit(X_train, y_train)\n\n# Делаем предсказания на тестовой выборке\n# Тестовая выборка НЕ использовалась при обучении и выборе модели\ny_pred = best_model.predict(X_test)\n\n# Считаем финальную метрику на тесте\n# Это честная оценка качества модели на новых данных\ntest_accuracy = accuracy_score(y_test, y_pred)\nprint(f\"Точность на тестовой выборке: {test_accuracy:.5f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Матрица ошибок (Confusion Matrix)\n# Показывает сколько образцов каждого класса были классифицированы в каждый класс\n# Диагональ - правильные предсказания\n# Вне диагонали - ошибки (путаницы между классами)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Матрица ошибок (Confusion Matrix):\")\nprint(\"Строки - истинные классы, столбцы - предсказанные\")\nprint(cm)\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Анализ ошибок по дням недели\n# Вычисляем процент ошибок для каждого дня\n# Это помогает понять, для каких классов модель работает хуже\n\nweekdays = sorted(y_test.unique())\nerror_rates = {}\n\nfor day in weekdays:\n    # Получаем все образцы данного дня\n    day_mask = (y_test == day)\n    day_total = day_mask.sum()  # Всего образцов этого дня\n    \n    # Считаем ошибки - образцы этого дня, которые предсказаны неверно\n    day_errors = ((y_test == day) & (y_pred != day)).sum()\n    \n    # Процент ошибок от общего числа образцов этого класса\n    error_rate = (day_errors / day_total * 100) if day_total > 0 else 0\n    error_rates[day] = error_rate\n    \n    print(f\"День {day}: {day_errors}/{day_total} ошибок ({error_rate:.2f}%)\")\n\n# Находим день с максимальным процентом ошибок\nworst_day = max(error_rates, key=error_rates.get)\nprint(f\"\\nХуже всего модель предсказывает день: {worst_day}\")\nprint(f\"Процент ошибок для этого дня: {error_rates[worst_day]:.2f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Сохранение лучшей модели с помощью pickle\n# pickle - стандартный способ сериализации объектов Python\n# Сохраненную модель можно загрузить позже для предсказаний без повторного обучения\n\nmodel_filename = '../data/best_model_ex00.pkl'\n\n# Открываем файл для записи в бинарном режиме ('wb')\nwith open(model_filename, 'wb') as f:\n    pickle.dump(best_model, f)  # Сериализуем и записываем модель\n    \nprint(f\"Модель сохранена в файл: {model_filename}\")\nprint(f\"Для загрузки используйте: model = pickle.load(open('{model_filename}', 'rb'))\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}